# check if neither are censored
if(event[i]==1 & event[j]==1){
permissible <- permissible+1
# check if scores are tied
if(scores[i]==scores[j]){
ties = ties + 1}
# check for concordant
else if(scores[i]>scores[j] & y_true[i]<y_true[j]){
concordant = concordant + 1}
else if(scores[i]<scores[j] & y_true[j]<y_true[i]){
concordant = concordant + 1}
# check if one is censored
}
else if(event[i]==0 | event[j]==0){
# get censored index
censored = j
uncensored = i
if(event[i] == 0){
censored = i
uncensored = j}
# check if permissible
# Note: in this case, we are assuming that censored at a time
# means that you did NOT die at that time. That is, if you
# live until time 30 and have event = 0, then you lived THROUGH
# time 30.
if(y_true[uncensored] <= y_true[censored]){
permissible <- permissible+1
# check if scores are tied
if(scores[uncensored]==scores[censored]){
# update ties
ties = ties + 1}
# check if scores are concordant
if(scores[uncensored]>scores[censored]){
concordant = concordant + 1}
}}
# set result to c-index computed from number of concordant pairs,
# number of ties, and number of permissible pairs (REPLACE 0 with your␣→code
}}}
result = (concordant + (0.5 * ties)) / permissible
return(result)
}
y_true <-  c(30, 30, 20, 20)
event <-  c(1, 0, 1, 0)
scores <-  c(10, 5, 15, 20)
harell_c(y_true,scores,event)
harrell_c(y_true,scores,event)
# Function for c-index:
harrell_c <- function(y_true, scores, event){
# '''
# Compute Harrel C-index given true event/censoring times,
# model output, and event indicators.
# Args:
# y_true (array): array of true event times
# scores (array): model risk scores
# event (array): indicator, 1 if event occurred at that index, 0 for␣
# ,→censorship
# Returns:
# result (float): C-index metric
# '''
n = length(y_true)
#assert (len(scores) == n and len(event) == n)
concordant = 0.0
permissible = 0.0
ties = 0.0
result = 0.0
### START CODE HERE (REPLACE INSTANCES OF 'None' and 'pass' with your code)␣→###
# use double for loop to go through cases
for (i in 1:n){
# set lower bound on j to avoid double counting
for(j in (i+1): n){
# check if at most one is censored
if(event[i]==1 | event[j]==1){
# check if neither are censored
if(event[i]==1 & event[j]==1){
permissible <- permissible+1
# check if scores are tied
if(scores[i]==scores[j]){
ties = ties + 1}
# check for concordant
else if(scores[i]>scores[j] & y_true[i]<y_true[j]){
concordant = concordant + 1}
else if(scores[i]<scores[j] & y_true[j]<y_true[i]){
concordant = concordant + 1}
# check if one is censored
}
else if(event[i]==0 | event[j]==0){
# get censored index
censored = j
uncensored = i
if(event[i] == 0){
censored = i
uncensored = j}
# check if permissible
# Note: in this case, we are assuming that censored at a time
# means that you did NOT die at that time. That is, if you
# live until time 30 and have event = 0, then you lived THROUGH
# time 30.
if(y_true[uncensored] <= y_true[censored]){
permissible <- permissible+1
# check if scores are tied
if(scores[uncensored]==scores[censored]){
# update ties
ties = ties + 1}
# check if scores are concordant
if(scores[uncensored]>scores[censored]){
concordant = concordant + 1}
}}
# set result to c-index computed from number of concordant pairs,
# number of ties, and number of permissible pairs (REPLACE 0 with your␣→code
}}}
result = (concordant + (0.5 * ties)) / permissible
return(result)
}
harrell_c(y_true,scores,event)
library(randomForestSRC)
data <- read.csv('C:/Users/ngocdung/Dropbox/MCC/Admin/Entry and scoring.csv', stringAsFactor = F)
rm(list = ls())
library(tidyverse)
data <- read.csv('C:/Users/ngocdung/Dropbox/MCC/Admin/Entry and scoring.csv', stringAsFactor = F)
data <- read.csv('C:/Users/ngocdung/Dropbox/MCC/Admin/Entry and scoring.csv', stringsAsFactor = F)
library(ggplot2)
data %>%
#  filter(country == "United States") %>%
ggplot(aes(stylist, avg_score)) +
geom_bar()
glimpse(data)
data %>%
#  filter(country == "United States") %>%
ggplot(aes(stylist)) +
geom_bar(stat="avg_score")
data %>%
#  filter(country == "United States") %>%
ggplot() +
geom_bar(stat="avg_score",
position = "stylist",)
data %>%
#  filter(country == "United States") %>%
ggplot(avg_score, aes(stylist)) +
geom_bar()
data %>%
#  filter(country == "United States") %>%
ggplot(aes(stylist)) +
geom_bar()
data %>%
#  filter(country == "United States") %>%
ggplot(aes(stylist, avg_score)) +
geom_bar()
data %>%
#  filter(country == "United States") %>%
ggplot(aes(stylist, avg_score)) +
geom_col()
data %>%
#  filter(country == "United States") %>%
ggplot(aes(stylist, na.omit(avg_score))) +
geom_col()
View(data)
View(data)
data %>%
filter(!is.na(avg_score)) %>%
ggplot(aes(stylist, avg_score)) +
geom_col()
data %>%
filter(!is.na(avg_score)) %>%
group_by(stylist) %>%
summary(mean_score=mean(avg_score))
data %>%
filter(!is.na(avg_score)) %>%
group_by(stylist) %>%
summarize(mean_score=mean(avg_score))
data %>%
filter(!is.na(avg_score)) %>%
group_by(stylist) %>%
summarize(average_score=mean(avg_score))
data %>%
data %>%
data %>%
filter(!is.na(avg_score)) %>%
group_by(stylist) %>%
summarize(average_score=mean(avg_score)) %>%
ggplot(aes(stylist, avg_score = average_score)) +
geom_col()
data %>%
filter(!is.na(avg_score)) %>%
group_by(stylist) %>%
summarize(average_score=mean(avg_score)) %>%
ggplot(aes(stylist, average_score)) +
geom_col()
data %>%
filter(!is.na(avg_score)) %>%
group_by(stylist) %>%
summarize(average_score=mean(avg_score))
data %>%
filter(!is.na(avg_score)) %>%
group_by(slot) %>%
summarize(average_score=mean(avg_score)) %>%
ggplot(aes(slot, average_score)) +
geom_col()
data %>%
filter(!is.na(avg_score)) %>%
group_by(slot) %>%
summarize(average_score=mean(avg_score)) %>%
ggplot(aes(as.factor(slot), average_score)) +
geom_col()
# Slot - entry
data %>%
filter(!is.na(total_entry)) %>%
# group_by(slot) %>%
# summarize(=mean(total_entry)) %>%
ggplot(aes(as.factor(slot), total_entry)) +
geom_col()
# Slot - score
data %>%
filter(!is.na(avg_score)) %>%
group_by(slot) %>%
summarize(average_score=mean(avg_score)) %>%
ggplot(aes(as.factor(slot), average_score)) +
geom_col() +
ggtitle('Average score by Slot')
# Slot - entry
data %>%
filter(!is.na(total_entry)) %>%
group_by(slot) %>%
summarize(avg_entry=mean(total_entry)) %>%
ggplot(aes(as.factor(slot), avg_entry)) +
geom_col() +
ggtitle('Average number of entries by Slot')
data %>% geom_bar(sum(vlcv), sum(lcv), sum(mcv))
geom_bar(sum(data$vlcv), sum(data$lcv), sum(data$mcv))
geom_bar(aes(sum(data$vlcv), sum(data$lcv), sum(data$mcv)))
sum(data$vlcv)
geom_bar(aes(sum(data$vlcv_no), sum(data$lcv_no), sum(data$mcv_no)))
sum(data$vlcv_no)
glimpse(data)
# Entry by stylist
data %>%
filter(!is.na(total_entry)) %>%
group_by(stylist) %>%
summarize(avg_entry=mean(total_entry)) %>%
ggplot(aes(stylist, avg_entry)) +
geom_col() +
ggtitle('Average number of entries by Stylist')
.libPaths()
?install.packages
install.packages('randomForestSRC', dep = TRUE)
loadNamespace('randomSurvivalSRC')
loadNamespace('randomForestSRC')
R.home()
.libPaths()
sd(c(58, 89,65, 78, 55,26,93,46,43,59))
1.96*11/6
3.59+22
2/sqrt(3)
-.48/sqrt(3)
sqrt(3)
a = c(65    ,	78,    	52,    	82,    	92,    	89,    	73,    	98,    	56,    	76 )
b= c( 39,   	43,	21,	64,	57,	47,	27,	75,	34,	52,
)
b= c( 39,   	43,	21,	64,	57,	47,	27,	75,	34,	52)
lm(a, b)
lm(b~a)
lm(a~b)
122/11
95+27*3
176/11
18*11-81
117/33
117/3
39*3
117-18
18*11-81
39*3-18
7-18
77+18
18*11-81
117/33
66-27
117/3
39*3-18
77+18
6*3
1.25*20000
sqrt(8^2-4^2)
1000/2.5
400*0.5
4/3
sqrt(3-5*x+x^2+x^3)/(x-1)
x = 1.1
sqrt(3-5*x+x^2+x^3)/(x-1)
x = 1.01
sqrt(3-5*x+x^2+x^3)/(x-1)
x = 1.001
sqrt(3-5*x+x^2+x^3)/(x-1)
a = c(106, 110, 108, 112, 128, 96, 103, 110, 117, 109)
sd(a)
x = c( 1,	2,	3,	4,	5,	6,	7,	8)
y = c(590,   	750,   	1215,  	1335,  	1830,  	1920,  	2265,  	2670
)
glm(x,y)
lm(y~x)
lm(x~)
lm(x~y)
## ------------------------------------------------------------
## White wine classification example
## ------------------------------------------------------------
## load the data
data(wine, package = "randomForestSRC")
wine$quality <- factor(wine$quality)
## default tuning call
o <- tune(quality ~ ., wine, doBest = TRUE)
library(randomForestSRC)
wine$quality <- factor(wine$quality)
## default tuning call
o <- tune(quality ~ ., wine, doBest = TRUE)
## here is the optimized forest
print(o$rf)
## visualize the nodesize/mtry OOB surface
if (library("akima", logical.return = TRUE)) {
## nice little wrapper for plotting results
plot.tune <- function(o, linear = TRUE) {
x <- o$results[,1]
y <- o$results[,2]
z <- o$results[,3]
so <- interp(x=x, y=y, z=z, linear = linear)
idx <- which.min(z)
x0 <- x[idx]
y0 <- y[idx]
filled.contour(x = so$x,
y = so$y,
z = so$z,
xlim = range(so$x, finite = TRUE) + c(-2, 2),
ylim = range(so$y, finite = TRUE) + c(-2, 2),
color.palette =
colorRampPalette(c("yellow", "red")),
xlab = "nodesize",
ylab = "mtry",
main = "error rate for nodesize and mtry",
key.title = title(main = "OOB error", cex.main = 1),
plot.axes = {axis(1);axis(2);points(x0,y0,pch="x",cex=1,font=2);
points(x,y,pch=16,cex=.25)})
}
## plot the surface
plot.tune(o)
}
# Random forest ####
library(randomForestSRC)
?tune.rfsrc
?rfsrc
a <- c()
a
a.append(1)
rm(list = ls())
#memory.limit(size=20000)
library(tidyverse)
library(lubridate)
library(caret)
library(survival)
library(Hmisc)
#library(rms)
setwd("C:/Users/ngocdung/Dropbox/Front-end developer/src/data-science-path/udacity-nanodegree/Project 3/Assignment")
train <- read.csv("./Creditworthiness/credit-data-training.csv", stringsAsFactors=F)
test <- read.csv("./Creditworthiness/customers-to-score.csv", stringsAsFactors=F)
glimpse(train)
glimpse(test)
?prcorr
apply(train, unique)
sapply(train,2, unique)
sapply(train, unique)
cor(train[num_cols])
num_cols = c('Duration.of.Credit.Month', 'Credit.Amount', 'Age.years') #exclude outcome and potential factors
factor = c('Instalment.per.cent',
'Duration.in.Current.address',
'Most.valuable.available.asset',
'Type.of.apartment',
'Occupation',
'No.of.dependents',
'Telephone',
'Foreign.Worker')  #?
cor(train[num_cols])
colnames(train)
cor(train[c(num_cols,factor)])
head(train$Age.years)
View(train$Age.years)
length(train$Age.years)
sum(is.na(train$Age.years))
sapply(train, sum(is.na()))
sapply(train, sum(is.na))
for(col in train){
for col in train:
sum(is.na(col))
for(col in train){
sum(is.na(col))}
isna = vector(length(train))
i=1
for(col in train){
sum(is.na(col))
i = i + 1 }
?vector
isna = vector(length = length(train))
i=1
for(col in train){
sum(is.na(col))
i = i + 1 }
isna
for(col in train){
isna[i] = sum(is.na(col))
i = i + 1 }
isna
colnames(isna) <- colnames(train)
names(isna) <- colnames(train)
isna
isna = vector(length = length(train))
i=1
for(col in train){
isna[i] = sum(is.na(col))
i = i + 1 }
rownames(isna) <- colnames(train)
print(data.frame(colnames(train), isna)
)
unique(train$Duration.in.Current.address)
train$Age.years[train$Age.years==NA]
View(train$Age.years[train$Age.years==NA])
head(train$Age.years)
View(train['Age.years'][train$Age.years==NA])
View(train['Age.years'])
unique(train$Telephone)
View(train$Telephone[train$Telephone==1])
View(train$Telephone[train$Telephone==2])
View(train[train$Telephone==1])
View(is.na(train['Age.years']))
train$Telephone[train$Telephone==1] <- 12
unique(train$Telephone)
?str_replace_all
col_rename <- function(list){
for(item in list){
str_replace_all(item, '\\.', '_')
}
}
col_rename(colnames(train))
colnames(train)
col_rename <- function(list){
for(item in list){
item <- str_replace_all(item, '\\.', '_')
}
}
col_rename(colnames(train))
colnames(train)
a <- col_rename(colnames(train))
a
a <- 'b.c'
col_rename(a)
a
col_rename <- function(list){
for(item in list){
item <- str_replace_all(item, '.', '_')
}
}
col_rename(a)
a
class(colnames(train))
a
str_replace_all(a, '.', '_')
a <- 'b.c'
str_replace_all(a, '\\.', '_')
a <- c('b.c', 'c.d')
col_rename <- function(list){
for(item in list){
item <- str_replace_all(item, '\\.', '_')
}
}
col_rename(a)
a
b <- col_rename(a)
b
col_rename <- function(list){
for(item in list){
str_replace_all(item, '\\.', '_')
}
}
b <- col_rename(a)
b
col_rename(a)
a
str_replace_all(a, '\\.', '_')
str_replace_all(colnames(train), '\\.', '_')
colnames(train) <- str_replace_all(colnames(train), '\\.', '_')
colnames(test) <- str_replace_all(colnames(test), '\\.', '_')
glimpse(train)
glimpse(test)
setwd("C:/Users/ngocdung/Dropbox/Front-end developer/src/data-science-path/udacity-nanodegree/Project 3/Assignment")
train <- read.csv("./Creditworthiness/credit-data-training.csv", stringsAsFactors=F)
test <- read.csv("./Creditworthiness/customers-to-score.csv", stringsAsFactors=F)
colnames(train) <- str_replace_all(colnames(train), '\\.', '_')
colnames(test) <- str_replace_all(colnames(test), '\\.', '_')
View(train$Age_years[train$Age_years==1])
View(train$Age_years[train$Age_years==NA])
View(train$Age_years[is.na(train$Age_years)])
View(train[is.na(train$Age_years),c["Credit_Application_Result","Age_years"]])
View(train[is.na(train$Age_years),c("Credit_Application_Result","Age_years")])
median(train$Age_years)
median(train$Age_years[!is.na(train$Age_years)])
train$Age_years[is.na(train$Age_years)] <- median_age
median_age <- median(train$Age_years[!is.na(train$Age_years)])
train$Age_years[is.na(train$Age_years)] <- median_age
mean(train$Age_years)
colnames(train[-c('Duration_in_Current_address')])
colnames(train[,-c('Duration_in_Current_address')])
# Drop Duration_in_Current_address
train0 = subset(train, select = -c('Duration_in_Current_address') )
# Drop Duration_in_Current_address
train0 = train[,!(colnames(train) %in% c('Duration_in_Current_address'))]
colnames(train0)
colnames(train)
