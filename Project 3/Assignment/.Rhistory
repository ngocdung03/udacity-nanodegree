forest['Accuracy_worthy'] <- confusionMatrix(data = y_hat3w, reference = test$worthy)$overall["Accuracy"]
set.seed(1)
model3n <- train(nonworthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'worthy')],
method='rf',
ntree=500)
y_hat3n <- predict(model3n, test)
forest['Accuracy_nonworthy'] <- confusionMatrix(data = y_hat3n, reference = test$nonworthy)$overall["Accuracy"]
vi3 <- varImp(model3, scale = F)   #pvalue
plot3 <- ggplot(vi3, top = dim(vi3$importance)[1]) +
ggtitle('Variable Importance - Random Forest')
# Boosted model - Boosted Classification Trees
boosted <- vector()
# Data have to be re-formatted for bst() function
train4 <- train %>% mutate(#Credit_Application_Result= as.numeric(Credit_Application_Result),
Account_Balance= as.factor(as.numeric(Account_Balance)),
Payment_Status_of_Previous_Credit=as.factor(as.numeric(Payment_Status_of_Previous_Credit)),
Purpose=as.factor(as.numeric(Purpose)),
Value_Savings_Stocks=as.factor(as.numeric(Value_Savings_Stocks)),
Length_of_current_employment=as.factor(as.numeric(Length_of_current_employment)),
No_of_Credits_at_this_Bank=as.factor(as.numeric(No_of_Credits_at_this_Bank)),
)
test4 <- test %>% mutate(#Credit_Application_Result= as.numeric(Credit_Application_Result),
Account_Balance= as.factor(as.numeric(Account_Balance)),
Payment_Status_of_Previous_Credit=as.factor(as.numeric(Payment_Status_of_Previous_Credit)),
Purpose=as.factor(as.numeric(Purpose)),
Value_Savings_Stocks=as.factor(as.numeric(Value_Savings_Stocks)),
Length_of_current_employment=as.factor(as.numeric(Length_of_current_employment)),
No_of_Credits_at_this_Bank=as.factor(as.numeric(No_of_Credits_at_this_Bank)),
)
control <- trainControl(method = "cv", number = 5)
set.seed(1)
model4 <- train(Credit_Application_Result~.,
data=train4[!colnames(train) %in% c('worthy', 'nonworthy')],
method="bstTree",
trControl = control)
y_hat4 <- predict(model4, test4)
y_hat40 <- predict(model4, train4)
boosted['Accuracy_train'] <- confusionMatrix(data = y_hat40, reference = train4$Credit_Application_Result)$overall["Accuracy"]
boosted['Accuracy_test'] <- confusionMatrix(data = y_hat4, reference = test4$Credit_Application_Result)$overall["Accuracy"]
set.seed(1)
model4w <- train(worthy~.,
data=train4[!colnames(train) %in% c('Credit_Application_Result', 'nonworthy')],
method='bstTree',
trControl = control)
y_hat4w <- predict(model4w, test4)
boosted['Accuracy_worthy'] <- confusionMatrix(data = y_hat4w, reference = test4$worthy)$overall["Accuracy"]
set.seed(1)
model4n <- train(nonworthy~.,
data=train4[!colnames(train) %in% c('Credit_Application_Result', 'worthy')],
method='bstTree',
trControl = control)
y_hat4n <- predict(model4n, test4)
boosted['Accuracy_nonworthy'] <- confusionMatrix(data = y_hat4n, reference = test4$nonworthy)$overall["Accuracy"]
vi4 <- varImp(model4, scale = F)   #pvalue
plot4 <- ggplot(vi4, top = dim(vi4$importance)[1]) +
ggtitle('Variable Importance - Boosted Tree')
#Print confusion matrices
print(confusionMatrix(data = y_hat1, reference = test$Credit_Application_Result))
print(confusionMatrix(data = y_hat2, reference = test$Credit_Application_Result))
print(confusionMatrix(data = y_hat3, reference = test$Credit_Application_Result))
print(confusionMatrix(data = y_hat4, reference = test4$Credit_Application_Result))
?confusionMatrix
print(data.frame(lr, tree, forest, boosted)[c('Accuracy_train','Accuracy_test'),])
# Logistic regression
lr <- vector()
model1 <- train(Credit_Application_Result~.,
data=train[!colnames(train) %in% c('worthy', 'nonworthy')],
method='glm')  #check
y_hat1 <- predict(model1, test)
y_hat10 <- predict(model1, train)
lr['Accuracy_train'] <- confusionMatrix(data = y_hat10, reference = train$Credit_Application_Result)$overall["Accuracy"] #Bias
lr['Accuracy_test'] <- confusionMatrix(data = y_hat1, reference = test$Credit_Application_Result)$overall["Accuracy"]
model1w <- train(worthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'nonworthy')],
method='glm')
y_hat1w <- predict(model1w, test)
lr['Accyracy_worthy'] <- confusionMatrix(data = y_hat1w, reference = test$worthy)$overall["Accuracy"]
model1n <- train(nonworthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'worthy')],
method='glm')
y_hat1n <- predict(model1n, test)
lr['Accuracy_nonworthy'] <- confusionMatrix(data = y_hat1n, reference = test$nonworthy)$overall["Accuracy"]
vi1 <- varImp(model1, scale = F)   #pvalue
plot1 <- ggplot(vi1, top = dim(vi1$importance)[1]) +
ggtitle('Variable Importance - Logistic Regression')
# Decision tree
tree <- vector()
model2 <- train(Credit_Application_Result~.,
data=train[!colnames(train) %in% c('worthy', 'nonworthy')],
method='rpart')
y_hat2 <- predict(model2, test)
y_hat20 <- predict(model2, train)
tree['Accuracy_train'] <- confusionMatrix(data = y_hat20, reference = train$Credit_Application_Result)$overall["Accuracy"]
tree['Accuracy_test'] <- confusionMatrix(data = y_hat2, reference = test$Credit_Application_Result)$overall["Accuracy"]
model2w <- train(worthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'nonworthy')],
method='rpart')
y_hat2w <- predict(model2w, test)
tree['Accuracy_worthy'] <- confusionMatrix(data = y_hat2w, reference = test$worthy)$overall["Accuracy"]
model2n <- train(nonworthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'worthy')],
method='rpart')
y_hat2n <- predict(model2n, test)
tree['Accuracy_nonworthy'] <- confusionMatrix(data = y_hat2n, reference = test$nonworthy)$overall["Accuracy"]
vi2 <- varImp(model2, scale = F)
plot2 <- ggplot(vi2, top = dim(vi2$importance)[1]) +
ggtitle('Variable Importance - Decision Tree')
# Forest model
forest <- vector()
set.seed(1)
model3 <- train(Credit_Application_Result~.,
data=train[!colnames(train) %in% c('worthy', 'nonworthy')],
method='rf',
ntree=500)
y_hat3 <- predict(model3, test)
y_hat30 <- predict(model3, train)
forest['Accuracy_train'] <- confusionMatrix(data = y_hat30, reference = train$Credit_Application_Result)$overall["Accuracy"]
forest['Accuracy_test'] <- confusionMatrix(data = y_hat3, reference = test$Credit_Application_Result)$overall["Accuracy"]
set.seed(1)
model3w <- train(worthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'nonworthy')],
method='rf',
ntree=500)
y_hat3w <- predict(model3w, test)
forest['Accuracy_worthy'] <- confusionMatrix(data = y_hat3w, reference = test$worthy)$overall["Accuracy"]
set.seed(1)
model3n <- train(nonworthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'worthy')],
method='rf',
ntree=500)
y_hat3n <- predict(model3n, test)
forest['Accuracy_nonworthy'] <- confusionMatrix(data = y_hat3n, reference = test$nonworthy)$overall["Accuracy"]
vi3 <- varImp(model3, scale = F)   #pvalue
plot3 <- ggplot(vi3, top = dim(vi3$importance)[1]) +
ggtitle('Variable Importance - Random Forest')
# Boosted model - Boosted Classification Trees
boosted <- vector()
# Data have to be re-formatted for bst() function
train4 <- train %>% mutate(#Credit_Application_Result= as.numeric(Credit_Application_Result),
Account_Balance= as.factor(as.numeric(Account_Balance)),
Payment_Status_of_Previous_Credit=as.factor(as.numeric(Payment_Status_of_Previous_Credit)),
Purpose=as.factor(as.numeric(Purpose)),
Value_Savings_Stocks=as.factor(as.numeric(Value_Savings_Stocks)),
Length_of_current_employment=as.factor(as.numeric(Length_of_current_employment)),
No_of_Credits_at_this_Bank=as.factor(as.numeric(No_of_Credits_at_this_Bank)),
)
test4 <- test %>% mutate(#Credit_Application_Result= as.numeric(Credit_Application_Result),
Account_Balance= as.factor(as.numeric(Account_Balance)),
Payment_Status_of_Previous_Credit=as.factor(as.numeric(Payment_Status_of_Previous_Credit)),
Purpose=as.factor(as.numeric(Purpose)),
Value_Savings_Stocks=as.factor(as.numeric(Value_Savings_Stocks)),
Length_of_current_employment=as.factor(as.numeric(Length_of_current_employment)),
No_of_Credits_at_this_Bank=as.factor(as.numeric(No_of_Credits_at_this_Bank)),
)
control <- trainControl(method = "cv", number = 5)
set.seed(1)
model4 <- train(Credit_Application_Result~.,
data=train4[!colnames(train) %in% c('worthy', 'nonworthy')],
method="bstTree",
trControl = control)
y_hat4 <- predict(model4, test4)
y_hat40 <- predict(model4, train4)
boosted['Accuracy_train'] <- confusionMatrix(data = y_hat40, reference = train4$Credit_Application_Result)$overall["Accuracy"]
boosted['Accuracy_test'] <- confusionMatrix(data = y_hat4, reference = test4$Credit_Application_Result)$overall["Accuracy"]
set.seed(1)
model4w <- train(worthy~.,
data=train4[!colnames(train) %in% c('Credit_Application_Result', 'nonworthy')],
method='bstTree',
trControl = control)
y_hat4w <- predict(model4w, test4)
boosted['Accuracy_worthy'] <- confusionMatrix(data = y_hat4w, reference = test4$worthy)$overall["Accuracy"]
set.seed(1)
model4n <- train(nonworthy~.,
data=train4[!colnames(train) %in% c('Credit_Application_Result', 'worthy')],
method='bstTree',
trControl = control)
y_hat4n <- predict(model4n, test4)
boosted['Accuracy_nonworthy'] <- confusionMatrix(data = y_hat4n, reference = test4$nonworthy)$overall["Accuracy"]
vi4 <- varImp(model4, scale = F)   #pvalue
plot4 <- ggplot(vi4, top = dim(vi4$importance)[1]) +
ggtitle('Variable Importance - Boosted Tree')
#Print confusion matrices
print(confusionMatrix(data = y_hat1, reference = test$Credit_Application_Result))
print(confusionMatrix(data = y_hat2, reference = test$Credit_Application_Result))
print(confusionMatrix(data = y_hat3, reference = test$Credit_Application_Result))
print(confusionMatrix(data = y_hat4, reference = test4$Credit_Application_Result))
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE, error=TRUE)
setwd("C:/Users/ngocdung/Dropbox/Front-end developer/src/data-science-path/udacity-nanodegree/Project 3/Assignment")
raw <- read.csv("./Creditworthiness/credit-data-training.csv", stringsAsFactors=F)
validation <- read.csv("./Creditworthiness/customers-to-score.csv", stringsAsFactors=F)
library(tidyverse)
library(caret)
library(randomForest)
library(bst)
library(cowplot)
#raw <- read.csv("./Creditworthiness/credit-data-training.csv", stringsAsFactors=F)
#validation <- read.csv("./Creditworthiness/customers-to-score.csv", stringsAsFactors=F)
colnames(validation) <- str_replace_all(colnames(validation), '\\.', '_')
colnames(raw) <- str_replace_all(colnames(raw), '\\.', '_')
glimpse(raw)
isna = vector(length = length(raw))
i=1
for(col in raw){
isna[i] = sum(is.na(col))
i = i + 1 }
print(data.frame(field = colnames(raw), no_of_missing = isna))
raw = raw[,!(colnames(raw) %in% c('Duration_in_Current_address'))]
median_age <- median(raw$Age_years[!is.na(raw$Age_years)])
raw$Age_years[is.na(raw$Age_years)] <- median_age
mean(raw$Age_years)
print(list(count(raw, Occupation),
count(raw, No_of_dependents),
count(raw, Foreign_Worker),
count(raw, Guarantors),
count(raw, Concurrent_Credits)))
p1 <- histogram(raw$Occupation)
p2 <- histogram(raw$No_of_dependents)
p3 <- histogram(raw$Foreign_Worker)
p4 <- histogram(as.factor(raw$Guarantors))
p5 <- histogram(as.factor(raw$Concurrent_Credits))
plot_grid(p1, p2, p3, p4, p5)
numeric <-  c('Duration_of_Credit_Month',
'Credit_Amount',
'Age_years')
numeric2 <- c('Instalment_per_cent',
'Most_valuable_available_asset',
'Type_of_apartment')
factor <- c("Credit_Application_Result",
"Account_Balance",
"Payment_Status_of_Previous_Credit",
"Purpose",
"Value_Savings_Stocks",
"Length_of_current_employment",
"No_of_Credits_at_this_Bank")
raw <- data.frame(raw[c(numeric, numeric2)],
apply(raw[factor],2, as.factor))
print(cor(raw[c(numeric, numeric2)]))
data <- raw
glimpse(data)
data$worthy <- as.factor(ifelse(data$Credit_Application_Result == 'Creditworthy', 1, 0))
data$nonworthy <- as.factor(ifelse(data$Credit_Application_Result == 'Non-Creditworthy', 1, 0))
set.seed(1)
train.index <- createDataPartition(data$Credit_Application_Result, p = .7, list = FALSE)
train <- data[train.index,]
test <- data[-train.index,]
# Logistic regression
lr <- vector()
model1 <- train(Credit_Application_Result~.,
data=train[!colnames(train) %in% c('worthy', 'nonworthy')],
method='glm')  #check
y_hat1 <- predict(model1, test)
y_hat10 <- predict(model1, train)
lr['Accuracy_train'] <- confusionMatrix(data = y_hat10, reference = train$Credit_Application_Result)$overall["Accuracy"] #Bias
lr['Accuracy_test'] <- confusionMatrix(data = y_hat1, reference = test$Credit_Application_Result)$overall["Accuracy"]
model1w <- train(worthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'nonworthy')],
method='glm')
y_hat1w <- predict(model1w, test)
lr['Accyracy_worthy'] <- confusionMatrix(data = y_hat1w, reference = test$worthy)$overall["Accuracy"]
model1n <- train(nonworthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'worthy')],
method='glm')
y_hat1n <- predict(model1n, test)
lr['Accuracy_nonworthy'] <- confusionMatrix(data = y_hat1n, reference = test$nonworthy)$overall["Accuracy"]
vi1 <- varImp(model1, scale = F)   #pvalue
plot1 <- ggplot(vi1, top = dim(vi1$importance)[1]) +
ggtitle('Variable Importance - Logistic Regression')
# Decision tree
tree <- vector()
model2 <- train(Credit_Application_Result~.,
data=train[!colnames(train) %in% c('worthy', 'nonworthy')],
method='rpart')
y_hat2 <- predict(model2, test)
y_hat20 <- predict(model2, train)
tree['Accuracy_train'] <- confusionMatrix(data = y_hat20, reference = train$Credit_Application_Result)$overall["Accuracy"]
tree['Accuracy_test'] <- confusionMatrix(data = y_hat2, reference = test$Credit_Application_Result)$overall["Accuracy"]
model2w <- train(worthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'nonworthy')],
method='rpart')
y_hat2w <- predict(model2w, test)
tree['Accuracy_worthy'] <- confusionMatrix(data = y_hat2w, reference = test$worthy)$overall["Accuracy"]
model2n <- train(nonworthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'worthy')],
method='rpart')
y_hat2n <- predict(model2n, test)
tree['Accuracy_nonworthy'] <- confusionMatrix(data = y_hat2n, reference = test$nonworthy)$overall["Accuracy"]
vi2 <- varImp(model2, scale = F)
plot2 <- ggplot(vi2, top = dim(vi2$importance)[1]) +
ggtitle('Variable Importance - Decision Tree')
# Forest model
forest <- vector()
set.seed(1)
model3 <- train(Credit_Application_Result~.,
data=train[!colnames(train) %in% c('worthy', 'nonworthy')],
method='rf',
ntree=500)
y_hat3 <- predict(model3, test)
y_hat30 <- predict(model3, train)
forest['Accuracy_train'] <- confusionMatrix(data = y_hat30, reference = train$Credit_Application_Result)$overall["Accuracy"]
forest['Accuracy_test'] <- confusionMatrix(data = y_hat3, reference = test$Credit_Application_Result)$overall["Accuracy"]
set.seed(1)
model3w <- train(worthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'nonworthy')],
method='rf',
ntree=500)
y_hat3w <- predict(model3w, test)
forest['Accuracy_worthy'] <- confusionMatrix(data = y_hat3w, reference = test$worthy)$overall["Accuracy"]
set.seed(1)
model3n <- train(nonworthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'worthy')],
method='rf',
ntree=500)
y_hat3n <- predict(model3n, test)
forest['Accuracy_nonworthy'] <- confusionMatrix(data = y_hat3n, reference = test$nonworthy)$overall["Accuracy"]
vi3 <- varImp(model3, scale = F)   #pvalue
plot3 <- ggplot(vi3, top = dim(vi3$importance)[1]) +
ggtitle('Variable Importance - Random Forest')
# Boosted model - Boosted Classification Trees
boosted <- vector()
# Data have to be re-formatted for bst() function
train4 <- train %>% mutate(#Credit_Application_Result= as.numeric(Credit_Application_Result),
Account_Balance= as.factor(as.numeric(Account_Balance)),
Payment_Status_of_Previous_Credit=as.factor(as.numeric(Payment_Status_of_Previous_Credit)),
Purpose=as.factor(as.numeric(Purpose)),
Value_Savings_Stocks=as.factor(as.numeric(Value_Savings_Stocks)),
Length_of_current_employment=as.factor(as.numeric(Length_of_current_employment)),
No_of_Credits_at_this_Bank=as.factor(as.numeric(No_of_Credits_at_this_Bank)),
)
test4 <- test %>% mutate(#Credit_Application_Result= as.numeric(Credit_Application_Result),
Account_Balance= as.factor(as.numeric(Account_Balance)),
Payment_Status_of_Previous_Credit=as.factor(as.numeric(Payment_Status_of_Previous_Credit)),
Purpose=as.factor(as.numeric(Purpose)),
Value_Savings_Stocks=as.factor(as.numeric(Value_Savings_Stocks)),
Length_of_current_employment=as.factor(as.numeric(Length_of_current_employment)),
No_of_Credits_at_this_Bank=as.factor(as.numeric(No_of_Credits_at_this_Bank)),
)
control <- trainControl(method = "cv", number = 5)
set.seed(1)
model4 <- train(Credit_Application_Result~.,
data=train4[!colnames(train) %in% c('worthy', 'nonworthy')],
method="bstTree",
trControl = control)
y_hat4 <- predict(model4, test4)
y_hat40 <- predict(model4, train4)
boosted['Accuracy_train'] <- confusionMatrix(data = y_hat40, reference = train4$Credit_Application_Result)$overall["Accuracy"]
boosted['Accuracy_test'] <- confusionMatrix(data = y_hat4, reference = test4$Credit_Application_Result)$overall["Accuracy"]
set.seed(1)
model4w <- train(worthy~.,
data=train4[!colnames(train) %in% c('Credit_Application_Result', 'nonworthy')],
method='bstTree',
trControl = control)
y_hat4w <- predict(model4w, test4)
boosted['Accuracy_worthy'] <- confusionMatrix(data = y_hat4w, reference = test4$worthy)$overall["Accuracy"]
set.seed(1)
model4n <- train(nonworthy~.,
data=train4[!colnames(train) %in% c('Credit_Application_Result', 'worthy')],
method='bstTree',
trControl = control)
y_hat4n <- predict(model4n, test4)
boosted['Accuracy_nonworthy'] <- confusionMatrix(data = y_hat4n, reference = test4$nonworthy)$overall["Accuracy"]
vi4 <- varImp(model4, scale = F)   #pvalue
plot4 <- ggplot(vi4, top = dim(vi4$importance)[1]) +
ggtitle('Variable Importance - Boosted Tree')
#Print confusion matrices
print(confusionMatrix(data = y_hat1, reference = test$Credit_Application_Result))
print(confusionMatrix(data = y_hat2, reference = test$Credit_Application_Result))
print(confusionMatrix(data = y_hat3, reference = test$Credit_Application_Result))
print(confusionMatrix(data = y_hat4, reference = test4$Credit_Application_Result))
head(y_hat1)
class(y_hat1)
head(train$Credit_Application_Result)
class(train$Credit_Application_Result)
raw <- raw %>% mutate(Credit_Application_Result= as.factor(Credit_Application_Result),
Account_Balance= as.factor(Account_Balance),
Payment_Status_of_Previous_Credit=as.factor(Payment_Status_of_Previous_Credit),
Purpose=as.factor(Purpose),
Value_Savings_Stocks=as.factor(Value_Savings_Stocks),
Length_of_current_employment=as.factor(Length_of_current_employment),
No_of_Credits_at_this_Bank=as.factor(No_of_Credits_at_this_Bank))
data <- raw
glimpse(data)
data$worthy <- as.factor(ifelse(data$Credit_Application_Result == 'Creditworthy', 1, 0))
data$nonworthy <- as.factor(ifelse(data$Credit_Application_Result == 'Non-Creditworthy', 1, 0))
set.seed(1)
train.index <- createDataPartition(data$Credit_Application_Result, p = .7, list = FALSE)
train <- data[train.index,]
test <- data[-train.index,]
# Logistic regression
lr <- vector()
model1 <- train(Credit_Application_Result~.,
data=train[!colnames(train) %in% c('worthy', 'nonworthy')],
method='glm')  #check
y_hat1 <- predict(model1, test)
y_hat10 <- predict(model1, train)
lr['Accuracy_train'] <- confusionMatrix(data = y_hat10, reference = train$Credit_Application_Result)$overall["Accuracy"] #Bias
lr['Accuracy_test'] <- confusionMatrix(data = y_hat1, reference = test$Credit_Application_Result)$overall["Accuracy"]
model1w <- train(worthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'nonworthy')],
method='glm')
y_hat1w <- predict(model1w, test)
lr['Accyracy_worthy'] <- confusionMatrix(data = y_hat1w, reference = test$worthy)$overall["Accuracy"]
model1n <- train(nonworthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'worthy')],
method='glm')
y_hat1n <- predict(model1n, test)
lr['Accuracy_nonworthy'] <- confusionMatrix(data = y_hat1n, reference = test$nonworthy)$overall["Accuracy"]
vi1 <- varImp(model1, scale = F)   #pvalue
plot1 <- ggplot(vi1, top = dim(vi1$importance)[1]) +
ggtitle('Variable Importance - Logistic Regression')
# Decision tree
tree <- vector()
model2 <- train(Credit_Application_Result~.,
data=train[!colnames(train) %in% c('worthy', 'nonworthy')],
method='rpart')
y_hat2 <- predict(model2, test)
y_hat20 <- predict(model2, train)
tree['Accuracy_train'] <- confusionMatrix(data = y_hat20, reference = train$Credit_Application_Result)$overall["Accuracy"]
tree['Accuracy_test'] <- confusionMatrix(data = y_hat2, reference = test$Credit_Application_Result)$overall["Accuracy"]
model2w <- train(worthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'nonworthy')],
method='rpart')
y_hat2w <- predict(model2w, test)
tree['Accuracy_worthy'] <- confusionMatrix(data = y_hat2w, reference = test$worthy)$overall["Accuracy"]
model2n <- train(nonworthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'worthy')],
method='rpart')
y_hat2n <- predict(model2n, test)
tree['Accuracy_nonworthy'] <- confusionMatrix(data = y_hat2n, reference = test$nonworthy)$overall["Accuracy"]
vi2 <- varImp(model2, scale = F)
plot2 <- ggplot(vi2, top = dim(vi2$importance)[1]) +
ggtitle('Variable Importance - Decision Tree')
# Forest model
forest <- vector()
set.seed(1)
model3 <- train(Credit_Application_Result~.,
data=train[!colnames(train) %in% c('worthy', 'nonworthy')],
method='rf',
ntree=500)
y_hat3 <- predict(model3, test)
y_hat30 <- predict(model3, train)
forest['Accuracy_train'] <- confusionMatrix(data = y_hat30, reference = train$Credit_Application_Result)$overall["Accuracy"]
forest['Accuracy_test'] <- confusionMatrix(data = y_hat3, reference = test$Credit_Application_Result)$overall["Accuracy"]
set.seed(1)
model3w <- train(worthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'nonworthy')],
method='rf',
ntree=500)
y_hat3w <- predict(model3w, test)
forest['Accuracy_worthy'] <- confusionMatrix(data = y_hat3w, reference = test$worthy)$overall["Accuracy"]
set.seed(1)
model3n <- train(nonworthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'worthy')],
method='rf',
ntree=500)
y_hat3n <- predict(model3n, test)
forest['Accuracy_nonworthy'] <- confusionMatrix(data = y_hat3n, reference = test$nonworthy)$overall["Accuracy"]
vi3 <- varImp(model3, scale = F)   #pvalue
plot3 <- ggplot(vi3, top = dim(vi3$importance)[1]) +
ggtitle('Variable Importance - Random Forest')
# Boosted model - Boosted Classification Trees
boosted <- vector()
# Data have to be re-formatted for bst() function
train4 <- train %>% mutate(#Credit_Application_Result= as.numeric(Credit_Application_Result),
Account_Balance= as.factor(as.numeric(Account_Balance)),
Payment_Status_of_Previous_Credit=as.factor(as.numeric(Payment_Status_of_Previous_Credit)),
Purpose=as.factor(as.numeric(Purpose)),
Value_Savings_Stocks=as.factor(as.numeric(Value_Savings_Stocks)),
Length_of_current_employment=as.factor(as.numeric(Length_of_current_employment)),
No_of_Credits_at_this_Bank=as.factor(as.numeric(No_of_Credits_at_this_Bank)),
)
test4 <- test %>% mutate(#Credit_Application_Result= as.numeric(Credit_Application_Result),
Account_Balance= as.factor(as.numeric(Account_Balance)),
Payment_Status_of_Previous_Credit=as.factor(as.numeric(Payment_Status_of_Previous_Credit)),
Purpose=as.factor(as.numeric(Purpose)),
Value_Savings_Stocks=as.factor(as.numeric(Value_Savings_Stocks)),
Length_of_current_employment=as.factor(as.numeric(Length_of_current_employment)),
No_of_Credits_at_this_Bank=as.factor(as.numeric(No_of_Credits_at_this_Bank)),
)
control <- trainControl(method = "cv", number = 5)
set.seed(1)
model4 <- train(Credit_Application_Result~.,
data=train4[!colnames(train) %in% c('worthy', 'nonworthy')],
method="bstTree",
trControl = control)
y_hat4 <- predict(model4, test4)
y_hat40 <- predict(model4, train4)
boosted['Accuracy_train'] <- confusionMatrix(data = y_hat40, reference = train4$Credit_Application_Result)$overall["Accuracy"]
boosted['Accuracy_test'] <- confusionMatrix(data = y_hat4, reference = test4$Credit_Application_Result)$overall["Accuracy"]
set.seed(1)
model4w <- train(worthy~.,
data=train4[!colnames(train) %in% c('Credit_Application_Result', 'nonworthy')],
method='bstTree',
trControl = control)
y_hat4w <- predict(model4w, test4)
boosted['Accuracy_worthy'] <- confusionMatrix(data = y_hat4w, reference = test4$worthy)$overall["Accuracy"]
set.seed(1)
model4n <- train(nonworthy~.,
data=train4[!colnames(train) %in% c('Credit_Application_Result', 'worthy')],
method='bstTree',
trControl = control)
y_hat4n <- predict(model4n, test4)
boosted['Accuracy_nonworthy'] <- confusionMatrix(data = y_hat4n, reference = test4$nonworthy)$overall["Accuracy"]
vi4 <- varImp(model4, scale = F)   #pvalue
plot4 <- ggplot(vi4, top = dim(vi4$importance)[1]) +
ggtitle('Variable Importance - Boosted Tree')
#Print confusion matrices
print(confusionMatrix(data = y_hat1, reference = test$Credit_Application_Result))
print(confusionMatrix(data = y_hat2, reference = test$Credit_Application_Result))
print(confusionMatrix(data = y_hat3, reference = test$Credit_Application_Result))
print(confusionMatrix(data = y_hat4, reference = test4$Credit_Application_Result))
