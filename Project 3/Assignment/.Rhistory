count(raw, Occupation)  #1-500
count(raw, No_of_dependents)  #1-427, 2-73
count(raw, Telephone)
count(raw, Foreign_Worker)  #1-481, 2-19
count(raw, Credit_Application_Result)
count(raw, Account_Balance)
count(raw, Payment_Status_of_Previous_Credit)
count(raw, Purpose)  #Draw histo - temporarily accepted
count(raw, Value_Savings_Stocks)
count(raw, Length_of_current_employment)
count(raw, Guarantors)  #1-457, 2-43
count(raw, Concurrent_Credits)  #1-500
count(raw, No_of_Credits_at_this_Bank)
# data_scale <- scale(raw[c(num_cols, factor)], center = T, scale = T)
# apply(data_scale,2, var)
# 1.3. Identifying highly-correlate fields (at least 0.7)
factor1 <- c('Instalment_per_cent',    #? Can treat as ordered numeric
'Most_valuable_available_asset',
#'Telephone',
'Type_of_apartment')
remain1 <- c("Credit_Application_Result",
"Account_Balance",
"Payment_Status_of_Previous_Credit",
"Purpose",
"Value_Savings_Stocks",
"Length_of_current_employment",
"No_of_Credits_at_this_Bank")
raw <- raw %>% mutate(Credit_Application_Result= as.factor(Credit_Application_Result),
Account_Balance= as.factor(Account_Balance),
Payment_Status_of_Previous_Credit=as.factor(Payment_Status_of_Previous_Credit),
Purpose=as.factor(Purpose),
Value_Savings_Stocks=as.factor(Value_Savings_Stocks),
Length_of_current_employment=as.factor(Length_of_current_employment),
No_of_Credits_at_this_Bank=as.factor(No_of_Credits_at_this_Bank))
a <- cor(raw[c(num_cols,factor1,remain1)])
# a[a==1] <- 0
# max(a) #0.5739797
cor(raw[c(num_cols)])
data <- raw[c(num_cols,factor1,remain1)]
colnames(data)  #13
## 2. Train your Classification Models
#Bias/Fairness: Are Opportunity/Odds/Accuracy same across different groups ?
#Prediction bias = average of predictions - average of lables in dataset
#Is under predict = bias?
set.seed(1)
train.index <- createDataPartition(data$Credit_Application_Result, p = .7, list = FALSE)
train <- data[train.index,]  #351
test <- data[-train.index,]  #149
# Logistic regression
model1 <- train(Credit_Application_Result~., data=train, method='glm')  #check
y_hat1 <- predict(model1, test)
y_hat10 <- predict(model1, train)
confusionMatrix(data = y_hat1, reference = test$Credit_Application_Result)            #$overall["Accuracy"]
confusionMatrix(data = y_hat10, reference = train$Credit_Application_Result) #Bias
vi1 <- varImp(model1, scale = F)   #pvalue
ggplot(a, top = dim(a$importance)[1]) +
ggtitle('Variable Importance - Logistic Regression')
# Decision tree
model2 <- train(Credit_Application_Result~., data=train, method='rpart')
y_hat2 <- predict(model2, test)
y_hat20 <- predict(model2, train)
confusionMatrix(data = y_hat2, reference = test$Credit_Application_Result)
confusionMatrix(data = y_hat20, reference = train$Credit_Application_Result)
vi2 <- varImp(model2, scale = F)   #pvalue
ggplot(a, top = dim(a$importance)[1]) +
ggtitle('Variable Importance - Decision Tree')
# Forest model
model3 <- train(Credit_Application_Result~., data=train, method='rf')
y_hat3 <- predict(model3, test)
y_hat30 <- predict(model3, train)
confusionMatrix(data = y_hat3, reference = test$Credit_Application_Result)
confusionMatrix(data = y_hat30, reference = train$Credit_Application_Result)
vi3 <- varImp(model3, scale = F)   #pvalue
ggplot(a, top = dim(a$importance)[1]) +
ggtitle('Variable Importance - Random Forest')
model4 <- train(train[-1],
as.numeric(train$Credit_Application_Result),
method = 'bstTree',
learner='tree')
library(bst)
model4 <- train(train[-1],
as.numeric(train$Credit_Application_Result),
method = 'bstTree',
learner='tree')
# Boosted model
model4 <- bst(train[-1],
as.numeric(train$Credit_Application_Result),
learner='tree')  #Boosted Classification Trees
model4 <- train(x=train[-1],
y=as.numeric(train$Credit_Application_Result),
method = 'bstTree',
learner='tree')
train.bst
?train.bst
??train.bst
y_hat4c.importance()
model4 <- train(x=train[-1],
y=as.numeric(train$Credit_Application_Result),
method = 'ada')
model4 <- train(x=train[-1],
y=as.numeric(train$Credit_Application_Result),
method = 'ada',
learner='tree')
??vi()
vi(model4)
??vip()
install.packages('vip')
vi(model4)
library(vip)
vi(model4)
?vi
vi(y_hat4)
# Boosted model
set.seed(1)
model4 <- bst(train[-1],
as.numeric(train$Credit_Application_Result),
learner='tree')  #Boosted Classification Trees
y_hat4 <- predict(model4, test)
y_hat4c <- as.factor(ifelse(y_hat4<1.5, 1, 2))
y_hat40 <- predict(model4, train)
y_hat40c <- as.factor(ifelse(y_hat40<1.5, 1, 2))
vi(y_hat4)
vip(model4, vi(mtcars.ppr, method = "firm", ice = TRUE))
vip(model4, method = "firm", ice = TRUE)
vip(feature_names = model4, method = "firm", ice = TRUE)
vip(object = model4, method = "firm", ice = TRUE)
model5 <- train(as.numeric(train$Credit_Application_Result)~., data=train, method="bstTree")
model5 <- train(as.numeric(train$Credit_Application_Result)~., data=train, method="bstTree", learner='tree')
control <- trainControl(method = "cv", number = 5)
model5 <- train(as.numeric(train$Credit_Application_Result)~., data=train, method="bstTree", trControl=control)
warnings()
set.seed(118)
n <- nrow(iris)
trainindices <- sample(1:n, 0.8*n)
iris.train <- iris[trainindices,]
iris.test <- iris[-trainindices,]
control <- trainControl(method = "cv", number = 5)
fit.boost <- train(Species~., data=iris.train, method="bstTree", trControl=control)
class_prediction.boost <- predict(fit.boost, iris.test)
error.boost <- ModelMetrics::ce(iris.test$Species,class_prediction.boost)
error.boost
varImp(fit.boost)
head(iris.train$Species)
class(iris.train$Species)
model5 <- train(Credit_Application_Result~., data=train, method="bstTree", trControl=control)
model5 <- train(Credit_Application_Result~., data=train, method="bstTree")
glimpse(train)
glimpse(iris.train)
num_cols <-  c('Duration_of_Credit_Month', 'Credit_Amount', 'Age_years',
'Credit_Application_Result') #exclude outcome and potential factors
model5 <- train(Credit_Application_Result~., data=train[num_cols], method="bstTree")
varImp(model5)
# Boosted model
# In Alteryx default, max number of trees 4000, method to determine the final number of trees: Cross validation (5 folds, 1 machine core)
train4 <- train %>% mutate(Credit_Application_Result= as.numeric(Credit_Application_Result),
Account_Balance= as.numeric(Account_Balance),
Payment_Status_of_Previous_Credit=as.numeric(Payment_Status_of_Previous_Credit),
Purpose=as.numeric(Purpose),
Value_Savings_Stocks=as.numeric(Value_Savings_Stocks),
Length_of_current_employment=as.numeric(Length_of_current_employment),
No_of_Credits_at_this_Bank=as.numeric(No_of_Credits_at_this_Bank))
model5 <- train(Credit_Application_Result~., data=train, method="bstTree")
model5 <- train(Credit_Application_Result~., data=train4, method="bstTree")
# Boosted model
# In Alteryx default, max number of trees 4000, method to determine the final number of trees: Cross validation (5 folds, 1 machine core)
train4 <- train %>% mutate(#Credit_Application_Result= as.numeric(Credit_Application_Result),
Account_Balance= as.numeric(Account_Balance),
Payment_Status_of_Previous_Credit=as.numeric(Payment_Status_of_Previous_Credit),
Purpose=as.numeric(Purpose),
Value_Savings_Stocks=as.numeric(Value_Savings_Stocks),
Length_of_current_employment=as.numeric(Length_of_current_employment),
No_of_Credits_at_this_Bank=as.numeric(No_of_Credits_at_this_Bank))
model5 <- train(Credit_Application_Result~., data=train4, method="bstTree")
y_hat5 <- predict(model5, test)
y_hat5c <- as.factor(ifelse(y_hat5<1.5, 1, 2))
test4 <- test %>% mutate(#Credit_Application_Result= as.numeric(Credit_Application_Result),
Account_Balance= as.numeric(Account_Balance),
Payment_Status_of_Previous_Credit=as.numeric(Payment_Status_of_Previous_Credit),
Purpose=as.numeric(Purpose),
Value_Savings_Stocks=as.numeric(Value_Savings_Stocks),
Length_of_current_employment=as.numeric(Length_of_current_employment),
No_of_Credits_at_this_Bank=as.numeric(No_of_Credits_at_this_Bank))
y_hat5 <- predict(model5, test4)
y_hat5c <- as.factor(ifelse(y_hat5<1.5, 1, 2))
unique(y_hat5)
confusionMatrix(data = y_hat4c, reference = test$Credit_Application_Result)
confusionMatrix(data = y_hat4c, reference = test4$Credit_Application_Result)
confusionMatrix(data = y_hat5, reference = test4$Credit_Application_Result)
glimpse(train)
confusionMatrix(data = y_hat1, reference = test$Credit_Application_Result)            #$overall["Accuracy"]
train4 <- train %>% mutate(#Credit_Application_Result= as.numeric(Credit_Application_Result),
Account_Balance= as.factor(as.numeric(Account_Balance)),
Payment_Status_of_Previous_Credit=as.factor(as.numeric(Payment_Status_of_Previous_Credit)),
Purpose=as.factor(as.numeric(Purpose)),
Value_Savings_Stocks=as.factor(as.numeric(Value_Savings_Stocks)),
Length_of_current_employment=as.factor(as.numeric(Length_of_current_employment)),
No_of_Credits_at_this_Bank=as.factor(as.numeric(No_of_Credits_at_this_Bank)))
model5 <- train(Credit_Application_Result~., data=train4, method="bstTree")
test4 <- test %>% mutate(#Credit_Application_Result= as.numeric(Credit_Application_Result),
Account_Balance= as.factor(as.numeric(Account_Balance)),
Payment_Status_of_Previous_Credit=as.factor(as.numeric(Payment_Status_of_Previous_Credit)),
Purpose=as.factor(as.numeric(Purpose)),
Value_Savings_Stocks=as.factor(as.numeric(Value_Savings_Stocks)),
Length_of_current_employment=as.factor(as.numeric(Length_of_current_employment)),
No_of_Credits_at_this_Bank=as.factor(as.numeric(No_of_Credits_at_this_Bank)))
y_hat5 <- predict(model5, test4)
confusionMatrix(data = y_hat5, reference = test4$Credit_Application_Result)
glimpse(train4)
unique(train$Duration_of_Credit_Month)
unique(train$Instalment_per_cent)
unique(train$Most_valuable_available_asset)
unique(train$type)
unique(train$Type_of_apartment)
train4 <- train %>% mutate(#Credit_Application_Result= as.numeric(Credit_Application_Result),
Account_Balance= as.factor(as.numeric(Account_Balance)),
Payment_Status_of_Previous_Credit=as.factor(as.numeric(Payment_Status_of_Previous_Credit)),
Purpose=as.factor(as.numeric(Purpose)),
Value_Savings_Stocks=as.factor(as.numeric(Value_Savings_Stocks)),
Length_of_current_employment=as.factor(as.numeric(Length_of_current_employment)),
No_of_Credits_at_this_Bank=as.factor(as.numeric(No_of_Credits_at_this_Bank)),
Instalment_per_cent = as.factor(Instalment_per_cent),
Most_valuable_available_asset = as.factor(Most_valuable_available_asset),
Type_of_apartment = as.factor(Type_of_apartment))
test4 <- test %>% mutate(#Credit_Application_Result= as.numeric(Credit_Application_Result),
Account_Balance= as.factor(as.numeric(Account_Balance)),
Payment_Status_of_Previous_Credit=as.factor(as.numeric(Payment_Status_of_Previous_Credit)),
Purpose=as.factor(as.numeric(Purpose)),
Value_Savings_Stocks=as.factor(as.numeric(Value_Savings_Stocks)),
Length_of_current_employment=as.factor(as.numeric(Length_of_current_employment)),
No_of_Credits_at_this_Bank=as.factor(as.numeric(No_of_Credits_at_this_Bank)),
Instalment_per_cent = as.factor(Instalment_per_cent),
Most_valuable_available_asset = as.factor(Most_valuable_available_asset),
Type_of_apartment = as.factor(Type_of_apartment))
model5 <- train(Credit_Application_Result~., data=train4, method="bstTree")
y_hat5 <- predict(model5, test4)
confusionMatrix(data = y_hat5, reference = test4$Credit_Application_Result)
model1 <- train(Credit_Application_Result~., data=train4, method='glm')  #check
y_hat1 <- predict(model1, test4)
y_hat10 <- predict(model1, train4)
confusionMatrix(data = y_hat1, reference = test4$Credit_Application_Result)$overall["Accuracy"]
confusionMatrix(data = y_hat10, reference = train4$Credit_Application_Result)$overall["Accuracy"]
model2 <- train(Credit_Application_Result~., data=train4, method='rpart')
y_hat2 <- predict(model2, test4)
y_hat20 <- predict(model2, train4)
confusionMatrix(data = y_hat2, reference = test4$Credit_Application_Result)$overall["Accuracy"]
confusionMatrix(data = y_hat20, reference = train4$Credit_Application_Result)$overall["Accuracy"]
model1 <- train(Credit_Application_Result~., data=train, method='glm')  #check
y_hat1 <- predict(model1, test)
y_hat10 <- predict(model1, train)
confusionMatrix(data = y_hat1, reference = test$Credit_Application_Result)$overall["Accuracy"]
confusionMatrix(data = y_hat10, reference = train$Credit_Application_Result)$overall["Accuracy"] #Bi
model2 <- train(Credit_Application_Result~., data=train, method='rpart')
y_hat2 <- predict(model2, test)
y_hat20 <- predict(model2, train)
confusionMatrix(data = y_hat2, reference = test$Credit_Application_Result)$overall["Accuracy"]
confusionMatrix(data = y_hat20, reference = train$Credit_Application_Result)$overall["Accuracy"]
glimpse(train)
control <- trainControl(method = "cv", number = 5)
model5 <- train(Credit_Application_Result~., data=train4, method="bstTree", trcontrol = control)
model5 <- train(Credit_Application_Result~., data=train4, method="bstTree", trControl = control)
y_hat5 <- predict(model5, test4)
confusionMatrix(data = y_hat5, reference = test4$Credit_Application_Result)
y_hat50 <- predict(model5, train4)
confusionMatrix(data = y_hat50, reference = train4$Credit_Application_Result)
vi4 <- varImp(model5, scale = F)
ggplot(vi4, top = dim(a$importance)[1]) +
ggtitle('Variable Importance - Boosted Tree')
ggplot(vi4, top = dim(vi4$importance)[1]) +
ggtitle('Variable Importance - Boosted Tree')
confusionMatrix(data = y_hat4, reference = test4$Credit_Application_Result)
confusionMatrix(data = y_hat3, reference = test$Credit_Application_Result)
glimpse(train)
train2 <- train
train2$worthy <- ifelse(train2$Credit_Application_Result == 'Creditworthy', 1, 0)
train2$nonworthy <- ifelse(train2$Credit_Application_Result == 'Non-Creditworthy', 1, 0)
colnames(train2)
colnames(train2[!colnames(train2) %in% c('Credit_Application_Result', 'nonworthy')])
model100 <- train(Credit_Application_Result~.,
data=train2[!colnames(train2) %in% c('Credit_Application_Result', 'nonworthy')],
method='glm')
train2 <- train
train2$worthy <- ifelse(train2$Credit_Application_Result == 'Creditworthy', 1, 0)
train2$nonworthy <- ifelse(train2$Credit_Application_Result == 'Non-Creditworthy', 1, 0)
model100 <- train(Credit_Application_Result~.,
data=train2[!colnames(train2) %in% c('Credit_Application_Result', 'nonworthy')],
method='glm')
colnames(train2[!colnames(train2) %in% c('Credit_Application_Result', 'nonworthy')])
test2 <- test
test2$worthy <- ifelse(test2$Credit_Application_Result == 'Creditworthy', 1, 0)
test2$nonworthy <- ifelse(test2$Credit_Application_Result == 'Non-Creditworthy', 1, 0)
y_hat100 <- predict(model1, test2)
confusionMatrix(data = y_hat100, reference = test$worthy)$overall["Accuracy"]
confusionMatrix(data = y_hat100, reference = test2$worthy)$overall["Accuracy"]
model100 <- train(worthy~.,
data=train2[!colnames(train2) %in% c('Credit_Application_Result', 'nonworthy')],
method='glm')
y_hat100 <- predict(model1, test2)
confusionMatrix(data = y_hat100, reference = test2$worthy)$overall["Accuracy"]
train2 <- train
train2$worthy <- as.factor(ifelse(train2$Credit_Application_Result == 'Creditworthy', 1, 0))
train2$nonworthy <- as.factor(ifelse(train2$Credit_Application_Result == 'Non-Creditworthy', 1, 0))
test2 <- test
test2$worthy <- as.factor(ifelse(test2$Credit_Application_Result == 'Creditworthy', 1, 0))
test2$nonworthy <- as.factor(ifelse(test2$Credit_Application_Result == 'Non-Creditworthy', 1, 0))
model100 <- train(worthy~.,
data=train2[!colnames(train2) %in% c('Credit_Application_Result', 'nonworthy')],
method='glm')
y_hat100 <- predict(model1, test2)
confusionMatrix(data = y_hat100, reference = test2$worthy)$overall["Accuracy"]
head(test2$worthy)
glimpse(train2)
glimpse(test2)
y_hat100 <- predict(model1,
test2[!colnames(train2) %in% c('Credit_Application_Result', 'nonworthy')])
confusionMatrix(data = y_hat100, reference = test2$worthy)$overall["Accuracy"]
unique(y_hat100)
unique(test2$worthy)
y_hat100 <- predict(model100,
test2[!colnames(train2) %in% c('Credit_Application_Result', 'nonworthy')])
confusionMatrix(data = y_hat100, reference = test2$worthy)$overall["Accuracy"]
model1w <- train(worthy~.,
data=train2[!colnames(train2) %in% c('Credit_Application_Result', 'nonworthy')],
method='glm')
y_hat1w <- predict(model100,
test2)
confusionMatrix(data = y_hat1w, reference = test2$worthy)$overall["Accuracy"]
model1n <- train(nonworthy~.,
data=train2[!colnames(train2) %in% c('Credit_Application_Result', 'worthy')],
method='glm')
y_hat1n <- predict(model1n, test2)
confusionMatrix(data = y_hat1n, reference = test2$nonworthy)$overall["Accuracy"]
head(train2$nonworthy)
head(train2$worthy)
model2w <- train(worthy~.,
data=train2[!colnames(train2) %in% c('Credit_Application_Result', 'nonworthy')],
method='rpart')
y_hat2w <- predict(model2w, test2)
confusionMatrix(data = y_hat2w, reference = test2$worthy)$overall["Accuracy"]
model2n <- train(nonworthy~.,
data=train2[!colnames(train2) %in% c('Credit_Application_Result', 'worthy')],
method='rpart')
y_hat2n <- predict(model2n, test2)
confusionMatrix(data = y_hat2n, reference = test2$nonworthy)$overall["Accuracy"]
model2w <- train(worthy~.,
data=train2[!colnames(train2) %in% c('Credit_Application_Result', 'nonworthy')],
method='rpart')
y_hat2w <- predict(model2w, test2)
confusionMatrix(data = y_hat2w, reference = test2$worthy)#$overall["Accuracy"]
model2n <- train(nonworthy~.,
data=train2[!colnames(train2) %in% c('Credit_Application_Result', 'worthy')],
method='rpart')
y_hat2n <- predict(model2n, test2)
confusionMatrix(data = y_hat2n, reference = test2$nonworthy)#$overall["Accuracy"]
confusionMatrix(data = y_hat2w, reference = test2$worthy)$overall["Accuracy"]
confusionMatrix(data = y_hat2n, reference = test2$nonworthy)$overall["Accuracy"]
model1 <- train(Credit_Application_Result~.,
data=train[!colnames(train2) %in% c('worthy', 'nonworthy')],
method='glm')  #check
y_hat1 <- predict(model1, test)
y_hat10 <- predict(model1, train)
confusionMatrix(data = y_hat10, reference = train$Credit_Application_Result)$overall["Accuracy"] #Bias
confusionMatrix(data = y_hat1, reference = test$Credit_Application_Result)$overall["Accuracy"]
model1w <- train(worthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'nonworthy')],
method='glm')
y_hat1w <- predict(model1w, test)
confusionMatrix(data = y_hat1w, reference = test$worthy)$overall["Accuracy"]
model1n <- train(nonworthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'worthy')],
method='glm')
y_hat1n <- predict(model1n, test)
confusionMatrix(data = y_hat1n, reference = test2$nonworthy)$overall["Accuracy"]
data$worthy <- as.factor(ifelse(train2$Credit_Application_Result == 'Creditworthy', 1, 0))
data$nonworthy <- as.factor(ifelse(train2$Credit_Application_Result == 'Non-Creditworthy', 1, 0))
set.seed(1)
train.index <- createDataPartition(data$Credit_Application_Result, p = .7, list = FALSE)
train <- data[train.index,]  #351
test <- data[-train.index,]  #149
model1 <- train(Credit_Application_Result~.,
data=train[!colnames(train2) %in% c('worthy', 'nonworthy')],
method='glm')  #check
y_hat1 <- predict(model1, test)
y_hat10 <- predict(model1, train)
confusionMatrix(data = y_hat10, reference = train$Credit_Application_Result)$overall["Accuracy"] #Bias
confusionMatrix(data = y_hat1, reference = test$Credit_Application_Result)$overall["Accuracy"]
model1w <- train(worthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'nonworthy')],
method='glm')
y_hat1w <- predict(model1w, test)
confusionMatrix(data = y_hat1w, reference = test$worthy)$overall["Accuracy"]
model1n <- train(nonworthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'worthy')],
method='glm')
y_hat1n <- predict(model1n, test)
confusionMatrix(data = y_hat1n, reference = test2$nonworthy)$overall["Accuracy"]
data$worthy <- as.factor(ifelse(data$Credit_Application_Result == 'Creditworthy', 1, 0))
data$nonworthy <- as.factor(ifelse(data$Credit_Application_Result == 'Non-Creditworthy', 1, 0))
set.seed(1)
train.index <- createDataPartition(data$Credit_Application_Result, p = .7, list = FALSE)
train <- data[train.index,]  #351
test <- data[-train.index,]  #149
# Logistic regression
model1 <- train(Credit_Application_Result~.,
data=train[!colnames(train2) %in% c('worthy', 'nonworthy')],
method='glm')  #check
y_hat1 <- predict(model1, test)
y_hat10 <- predict(model1, train)
confusionMatrix(data = y_hat10, reference = train$Credit_Application_Result)$overall["Accuracy"] #Bias
confusionMatrix(data = y_hat1, reference = test$Credit_Application_Result)$overall["Accuracy"]
model1w <- train(worthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'nonworthy')],
method='glm')
y_hat1w <- predict(model1w, test)
confusionMatrix(data = y_hat1w, reference = test$worthy)$overall["Accuracy"]
model1n <- train(nonworthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'worthy')],
method='glm')
y_hat1n <- predict(model1n, test)
confusionMatrix(data = y_hat1n, reference = test$nonworthy)$overall["Accuracy"]
model2 <- train(Credit_Application_Result~., data=train, method='rpart')
y_hat2 <- predict(model2, test)
y_hat20 <- predict(model2, train)
confusionMatrix(data = y_hat20, reference = train$Credit_Application_Result)$overall["Accuracy"]
confusionMatrix(data = y_hat2, reference = test$Credit_Application_Result)$overall["Accuracy"]
model2w <- train(worthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'nonworthy')],
method='rpart')
y_hat2w <- predict(model2w, test)
confusionMatrix(data = y_hat2w, reference = test$worthy)$overall["Accuracy"]
model2n <- train(nonworthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'worthy')],
method='rpart')
y_hat2n <- predict(model2n, test)
confusionMatrix(data = y_hat2n, reference = test$nonworthy)$overall["Accuracy"]
model2 <- train(Credit_Application_Result~.,
data=train[!colnames(train) %in% c('worthy', 'nonworthy')],
method='rpart')
y_hat2 <- predict(model2, test)
y_hat20 <- predict(model2, train)
confusionMatrix(data = y_hat20, reference = train$Credit_Application_Result)$overall["Accuracy"]
confusionMatrix(data = y_hat2, reference = test$Credit_Application_Result)$overall["Accuracy"]
set.seed(1)
model3 <- train(Credit_Application_Result~.,
data=train[!colnames(train) %in% c('worthy', 'nonworthy')],
method='rf')
y_hat3 <- predict(model3, test)
y_hat30 <- predict(model3, train)
confusionMatrix(data = y_hat30, reference = train$Credit_Application_Result)$overall["Accuracy"]
confusionMatrix(data = y_hat3, reference = test$Credit_Application_Result)$overall["Accuracy"]
model3w <- train(worthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'nonworthy')],
method='rf')
y_hat3w <- predict(model3w, test)
confusionMatrix(data = y_hat3w, reference = test$worthy)$overall["Accuracy"]
model3n <- train(nonworthy~.,
data=train[!colnames(train) %in% c('Credit_Application_Result', 'worthy')],
method='rf')
y_hat3n <- predict(model3n, test)
confusionMatrix(data = y_hat3n, reference = test$nonworthy)$overall["Accuracy"]
vi3 <- varImp(model3, scale = F)   #pvalue
ggplot(vi3, top = dim(a$importance)[1]) +
ggtitle('Variable Importance - Random Forest')
# Boosted model - Boosted Classification Trees
# In Alteryx default, max number of trees 4000, method to determine the final number of trees: Cross validation (5 folds, 1 machine core)
# Must modify the data so that factor variablies -> numeric factor variables?
# model4 <- bst(train[-1],
#                 as.numeric(train$Credit_Application_Result),
#                 learner='tree')
train4 <- train %>% mutate(#Credit_Application_Result= as.numeric(Credit_Application_Result),
Account_Balance= as.factor(as.numeric(Account_Balance)),
Payment_Status_of_Previous_Credit=as.factor(as.numeric(Payment_Status_of_Previous_Credit)),
Purpose=as.factor(as.numeric(Purpose)),
Value_Savings_Stocks=as.factor(as.numeric(Value_Savings_Stocks)),
Length_of_current_employment=as.factor(as.numeric(Length_of_current_employment)),
No_of_Credits_at_this_Bank=as.factor(as.numeric(No_of_Credits_at_this_Bank)),
# Instalment_per_cent = as.factor(Instalment_per_cent),
# Most_valuable_available_asset = as.factor(Most_valuable_available_asset),
# Type_of_apartment = as.factor(Type_of_apartment)
)
test4 <- test %>% mutate(#Credit_Application_Result= as.numeric(Credit_Application_Result),
Account_Balance= as.factor(as.numeric(Account_Balance)),
Payment_Status_of_Previous_Credit=as.factor(as.numeric(Payment_Status_of_Previous_Credit)),
Purpose=as.factor(as.numeric(Purpose)),
Value_Savings_Stocks=as.factor(as.numeric(Value_Savings_Stocks)),
Length_of_current_employment=as.factor(as.numeric(Length_of_current_employment)),
No_of_Credits_at_this_Bank=as.factor(as.numeric(No_of_Credits_at_this_Bank)),
# Instalment_per_cent = as.factor(Instalment_per_cent),
# Most_valuable_available_asset = as.factor(Most_valuable_available_asset),
# Type_of_apartment = as.factor(Type_of_apartment)
)
control <- trainControl(method = "cv", number = 5)
set.seed(1)
model4 <- train(Credit_Application_Result~.,
data=train4[!colnames(train) %in% c('worthy', 'nonworthy')],
method="bstTree",
trControl = control)
y_hat4 <- predict(model4, test4)
y_hat40 <- predict(model4, train4)
confusionMatrix(data = y_hat40, reference = train4$Credit_Application_Result)$overall["Accuracy"]
confusionMatrix(data = y_hat4, reference = test4$Credit_Application_Result)$overall["Accuracy"]
model4w <- train(worthy~.,
data=train4[!colnames(train) %in% c('Credit_Application_Result', 'nonworthy')],
method='bstTree',
trControl = control)
y_hat4w <- predict(model4w, test4)
confusionMatrix(data = y_hat4w, reference = test4$worthy)$overall["Accuracy"]
model4n <- train(nonworthy~.,
data=train4[!colnames(train) %in% c('Credit_Application_Result', 'worthy')],
method='bstTree',
trControl = control)
y_hat4n <- predict(model4n, test4)
confusionMatrix(data = y_hat4n, reference = test4$nonworthy)$overall["Accuracy"]
